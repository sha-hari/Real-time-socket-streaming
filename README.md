# Real-time-socket-streaming

## Description: 
Buiding a real-time data engineering pipeline to process data using Big Data frameworks with Docker

## Technology used:
- Container: Docker
- Storage: Confluent Kafka Cloud
- Processing: Apache Spark, Elastic Search
- Environment: Pycharm 
  
## Process summary:
- Engineered a real-time data engineering pipeline over a TCP/IP socket data connection
- Implemented Apache Spark and Apache Kafka for robust data streaming and replication, ensuring high-throughput and reliable message delivery
- Achieved scalable data persistence, analysis using pyspark and pandas, visualization with Elasticsearch for indexing and Kibana/BI tools for interactive dashboarding
- Containerized the application using Docker
    
